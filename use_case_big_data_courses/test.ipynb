{
 "cells": [
  {
   "cell_type": "code",
   "id": "0d256b51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    },
    "ExecuteTime": {
     "end_time": "2025-11-06T09:57:43.161178Z",
     "start_time": "2025-11-06T09:57:42.176506Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:05:52.493205Z",
     "start_time": "2025-11-06T10:05:52.471269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "UDS Requirements Effort Estimation Model\n",
    "=========================================\n",
    "This script provides a machine learning model to estimate effort hours for\n",
    "implementing UDS (Unified Diagnostic Services) requirements.\n",
    "\n",
    "Author: Data Science Team\n",
    "Date: 2024\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "class UDSEffortEstimator:\n",
    "    \"\"\"\n",
    "    A machine learning model to estimate implementation effort for UDS diagnostic requirements.\n",
    "\n",
    "    This class uses Random Forest Regression to predict effort hours based on various\n",
    "    features of diagnostic requirements such as session type, service ID, security level, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the estimator with empty model and encoders.\"\"\"\n",
    "        self.model = None\n",
    "        self.encoder_session = LabelEncoder()\n",
    "        self.encoder_security = LabelEncoder()\n",
    "        self.encoder_dtc = LabelEncoder()\n",
    "        self.feature_columns = [\n",
    "            'Session_Type_encoded',\n",
    "            'Service_ID_numeric',\n",
    "            'Sub_function_numeric',\n",
    "            'Data_Identifier_count',\n",
    "            'Has_Routine_ID',\n",
    "            'DTC_Format_encoded',\n",
    "            'Status_Mask_numeric',\n",
    "            'Security_Level_encoded',\n",
    "            'Has_NRC_Code',\n",
    "            'Response_Time_ms_numeric'\n",
    "        ]\n",
    "        self.feature_importance_df = None\n",
    "\n",
    "    @staticmethod\n",
    "    def hex_to_int(value):\n",
    "        \"\"\"\n",
    "        Convert hexadecimal string to integer.\n",
    "\n",
    "        Args:\n",
    "            value: String value that may be hex (with '0x' prefix) or '-' for missing\n",
    "\n",
    "        Returns:\n",
    "            int: Converted integer value, or 0 if conversion fails\n",
    "        \"\"\"\n",
    "        if value == '-' or pd.isna(value):\n",
    "            return 0\n",
    "        try:\n",
    "            if isinstance(value, str) and value.startswith('0x'):\n",
    "                return int(value, 16)\n",
    "            return int(value)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def count_items(value):\n",
    "        \"\"\"\n",
    "        Count comma-separated items in a string.\n",
    "\n",
    "        Args:\n",
    "            value: String that may contain comma-separated values\n",
    "\n",
    "        Returns:\n",
    "            int: Number of items, or 0 if empty/missing\n",
    "        \"\"\"\n",
    "        if value == '-' or pd.isna(value):\n",
    "            return 0\n",
    "        return len(str(value).split(','))\n",
    "\n",
    "    def prepare_features(self, df, fit_encoders=True):\n",
    "        \"\"\"\n",
    "        Transform raw data into numerical features for the model.\n",
    "\n",
    "        This method performs the following transformations:\n",
    "        1. Converts hex values (Service_ID, Sub_function, Status_Mask) to integers\n",
    "        2. Counts multiple data identifiers\n",
    "        3. Creates binary features for presence of Routine_ID and NRC_Code\n",
    "        4. Encodes categorical variables (Session_Type, Security_Level, DTC_Format)\n",
    "        5. Handles Response_Time with missing values\n",
    "\n",
    "        Args:\n",
    "            df: pandas DataFrame with raw requirement data\n",
    "            fit_encoders: bool, whether to fit encoders (True for training, False for prediction)\n",
    "\n",
    "        Returns:\n",
    "            pandas DataFrame with prepared features\n",
    "        \"\"\"\n",
    "        df_prep = df.copy()\n",
    "\n",
    "        # Convert hexadecimal values to numeric\n",
    "        print(\"  Converting hexadecimal values...\")\n",
    "        df_prep['Service_ID_numeric'] = df_prep['Service_ID'].apply(self.hex_to_int)\n",
    "        df_prep['Sub_function_numeric'] = df_prep['Sub_function'].apply(self.hex_to_int)\n",
    "        df_prep['Status_Mask_numeric'] = df_prep['Status_Mask'].apply(self.hex_to_int)\n",
    "\n",
    "        # Count data identifiers (some requirements have multiple)\n",
    "        print(\"  Counting data identifiers...\")\n",
    "        df_prep['Data_Identifier_count'] = df_prep['Data_Identifier'].apply(self.count_items)\n",
    "\n",
    "        # Binary features: presence indicators\n",
    "        print(\"  Creating binary features...\")\n",
    "        df_prep['Has_Routine_ID'] = (df_prep['Routine_ID'] != '-').astype(int)\n",
    "        df_prep['Has_NRC_Code'] = (df_prep['NRC_Code'] != '-').astype(int)\n",
    "\n",
    "        # Handle Response Time (may have missing values represented as 0 or empty)\n",
    "        print(\"  Processing response time...\")\n",
    "        df_prep['Response_Time_ms_numeric'] = pd.to_numeric(df_prep['Response_Time_ms'], errors='coerce').fillna(0)\n",
    "\n",
    "        # Categorical encodings\n",
    "        print(\"  Encoding categorical variables...\")\n",
    "        if fit_encoders:\n",
    "            df_prep['Session_Type_encoded'] = self.encoder_session.fit_transform(df_prep['Session_Type'])\n",
    "            df_prep['Security_Level_encoded'] = self.encoder_security.fit_transform(df_prep['Security_Level'])\n",
    "            df_prep['DTC_Format_encoded'] = self.encoder_dtc.fit_transform(df_prep['DTC_Format'])\n",
    "        else:\n",
    "            df_prep['Session_Type_encoded'] = self.encoder_session.transform(df_prep['Session_Type'])\n",
    "            df_prep['Security_Level_encoded'] = self.encoder_security.transform(df_prep['Security_Level'])\n",
    "            df_prep['DTC_Format_encoded'] = self.encoder_dtc.transform(df_prep['DTC_Format'])\n",
    "\n",
    "        return df_prep\n",
    "\n",
    "    def train(self, df):\n",
    "        \"\"\"\n",
    "        Train the model on historical data.\n",
    "\n",
    "        Args:\n",
    "            df: pandas DataFrame with historical requirements data\n",
    "\n",
    "        Returns:\n",
    "            tuple: (mae, r2) - Mean Absolute Error and R¬≤ score\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Training Model ===\")\n",
    "\n",
    "        # Prepare features\n",
    "        print(\"Preparing features...\")\n",
    "        df_prep = self.prepare_features(df, fit_encoders=True)\n",
    "\n",
    "        # Extract features and target\n",
    "        X = df_prep[self.feature_columns]\n",
    "        y = df_prep['Effort_hours']\n",
    "\n",
    "        print(f\"Dataset shape: {X.shape}\")\n",
    "        print(f\"Target range: {y.min():.0f} - {y.max():.0f} hours\")\n",
    "\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.05, random_state=20\n",
    "        )\n",
    "\n",
    "        print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "        # Create and train model\n",
    "        print(\"\\nTraining Random Forest model...\")\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=20,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        print(\"\\nEvaluating model...\")\n",
    "        y_pred_train = self.model.predict(X_train)\n",
    "        y_pred_test = self.model.predict(X_test)\n",
    "\n",
    "        mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "        mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "        r2_train = r2_score(y_train, y_pred_train)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "        print(f\"\\n‚úÖ Model trained successfully!\")\n",
    "        print(f\"\\nTraining Performance:\")\n",
    "        print(f\"  Mean Absolute Error: {mae_train:.2f} hours\")\n",
    "        print(f\"  R¬≤ Score: {r2_train:.3f}\")\n",
    "        print(f\"\\nTest Performance:\")\n",
    "        print(f\"  Mean Absolute Error: {mae_test:.2f} hours\")\n",
    "        print(f\"  R¬≤ Score: {r2_test:.3f}\")\n",
    "\n",
    "        # Feature importance\n",
    "        self.feature_importance_df = pd.DataFrame({\n",
    "            'Feature': self.feature_columns,\n",
    "            'Importance': self.model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "\n",
    "        print(\"\\nüìä Top 5 Most Important Features:\")\n",
    "        for idx, row in self.feature_importance_df.head().iterrows():\n",
    "            print(f\"  {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "        return mae_test, r2_test\n",
    "\n",
    "    def predict(self, new_requirement):\n",
    "        \"\"\"\n",
    "        Predict effort for a new requirement.\n",
    "\n",
    "        Args:\n",
    "            new_requirement: dict with requirement attributes\n",
    "\n",
    "        Returns:\n",
    "            int: Predicted effort in hours (rounded)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet! Call train() first.\")\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        new_df = pd.DataFrame([new_requirement])\n",
    "\n",
    "        # Prepare features\n",
    "        new_df_prep = self.prepare_features(new_df, fit_encoders=False)\n",
    "\n",
    "        # Extract features\n",
    "        new_X = new_df_prep[self.feature_columns]\n",
    "\n",
    "        # Predict\n",
    "        effort = self.model.predict(new_X)[0]\n",
    "\n",
    "        return round(effort)\n",
    "\n",
    "    def plot_feature_importance(self, save_path='feature_importance.png'):\n",
    "        \"\"\"Plot and save feature importance chart.\"\"\"\n",
    "        if self.feature_importance_df is None:\n",
    "            print(\"No feature importance data available. Train the model first.\")\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(self.feature_importance_df['Feature'],\n",
    "                 self.feature_importance_df['Importance'],\n",
    "                 color='steelblue')\n",
    "        plt.xlabel('Importance', fontsize=12)\n",
    "        plt.ylabel('Feature', fontsize=12)\n",
    "        plt.title('Feature Importance for Effort Estimation', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\nüìà Feature importance plot saved to: {save_path}\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_residuals(self, save_path='residuals.png'):\n",
    "        fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "        ax[0].scatter(X_train, y_train, label=\"Train data points\")\n",
    "        ax[0].plot(\n",
    "            X_train,\n",
    "            regressor.predict(X_train),\n",
    "            linewidth=3,\n",
    "            color=\"tab:orange\",\n",
    "            label=\"Model predictions\",\n",
    "        )\n",
    "        ax[0].set(xlabel=\"Feature\", ylabel=\"Target\", title=\"Train set\")\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].scatter(X_test, y_test, label=\"Test data points\")\n",
    "        ax[1].plot(X_test, y_pred, linewidth=3, color=\"tab:orange\", label=\"Model predictions\")\n",
    "        ax[1].set(xlabel=\"Feature\", ylabel=\"Target\", title=\"Test set\")\n",
    "        ax[1].legend()\n",
    "\n",
    "        fig.suptitle(\"Linear Regression\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate the usage.\"\"\"\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"UDS REQUIREMENTS EFFORT ESTIMATION MODEL\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Check if CSV file exists\n",
    "    csv_file = 'uds_requirements_data.csv'\n",
    "    if not os.path.exists(csv_file):\n",
    "        print(f\"\\n‚ùå Error: CSV file '{csv_file}' not found!\")\n",
    "        print(\"Please ensure the CSV file is in the same directory as this script.\")\n",
    "        return\n",
    "\n",
    "    # Load data\n",
    "    print(f\"\\nüìÇ Loading data from {csv_file}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(f\"‚úÖ Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display basic info\n",
    "    print(\"\\nüìã Dataset Overview:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nüìä Dataset Statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # Create and train estimator\n",
    "    estimator = UDSEffortEstimator()\n",
    "    mae, r2 = estimator.train(df)\n",
    "\n",
    "    # Plot feature importance\n",
    "    estimator.plot_feature_importance()\n",
    "\n",
    "    # Example predictions\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXAMPLE PREDICTIONS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Example 1: Extended session with ReadDataByIdentifier\n",
    "    example1 = {\n",
    "        'Session_Type': 'Extended',\n",
    "        'Service_ID': '0x22',\n",
    "        'Sub_function': '-',\n",
    "        'Data_Identifier': '0xF190',\n",
    "        'Routine_ID': '-',\n",
    "        'DTC_Format': 'ISO15031-6',\n",
    "        'Status_Mask': '0x08',\n",
    "        'Security_Level': 'Unlocked',\n",
    "        'NRC_Code': '-',\n",
    "        'Response_Time_ms': 40\n",
    "    }\n",
    "\n",
    "    effort1 = estimator.predict(example1)\n",
    "    print(f\"\\nüîπ Example 1: Extended Session - ReadDataByIdentifier\")\n",
    "    print(f\"   Predicted effort: {effort1} hours\")\n",
    "\n",
    "    # Example 2: Programming session with RoutineControl\n",
    "    example2 = {\n",
    "        'Session_Type': 'Programming',\n",
    "        'Service_ID': '0x31',\n",
    "        'Sub_function': '0x01',\n",
    "        'Data_Identifier': '-',\n",
    "        'Routine_ID': '0x0200',\n",
    "        'DTC_Format': 'ISO15031-6',\n",
    "        'Status_Mask': '0x00',\n",
    "        'Security_Level': 'Unlocked',\n",
    "        'NRC_Code': '0x78',\n",
    "        'Response_Time_ms': 4750\n",
    "    }\n",
    "\n",
    "    effort2 = estimator.predict(example2)\n",
    "    print(f\"\\nüîπ Example 2: Programming Session - RoutineControl\")\n",
    "    print(f\"   Predicted effort: {effort2} hours\")\n",
    "\n",
    "    # Example 3: Default session with TesterPresent\n",
    "    example3 = {\n",
    "        'Session_Type': 'Default',\n",
    "        'Service_ID': '0x3E',\n",
    "        'Sub_function': '0x00',\n",
    "        'Data_Identifier': '-',\n",
    "        'Routine_ID': '-',\n",
    "        'DTC_Format': 'ISO15031-6',\n",
    "        'Status_Mask': '0x00',\n",
    "        'Security_Level': 'Locked',\n",
    "        'NRC_Code': '-',\n",
    "        'Response_Time_ms': 10\n",
    "    }\n",
    "\n",
    "    effort3 = estimator.predict(example3)\n",
    "    print(f\"\\nüîπ Example 3: Default Session - TesterPresent\")\n",
    "    print(f\"   Predicted effort: {effort3} hours\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ PROCESS COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\" * 70)"
   ],
   "id": "e18c62fdfed3dbfb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:05:54.028758Z",
     "start_time": "2025-11-06T10:05:53.621875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "9d25158da2a22c82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UDS REQUIREMENTS EFFORT ESTIMATION MODEL\n",
      "======================================================================\n",
      "\n",
      "üìÇ Loading data from uds_requirements_data.csv...\n",
      "‚úÖ Data loaded successfully: 66 rows, 12 columns\n",
      "\n",
      "üìã Dataset Overview:\n",
      "                Requirement_ID Session_Type Service_ID Sub_function  \\\n",
      "0  REQ_DIAG_Communication_0010      Default       0x10         0x01   \n",
      "1  REQ_DIAG_Communication_0020     Extended       0x22            -   \n",
      "2  REQ_DIAG_Communication_0030  Programming       0x27         0x01   \n",
      "3  REQ_DIAG_Communication_0040      Default       0x3E         0x00   \n",
      "4  REQ_DIAG_Communication_0050     Extended       0x2E            -   \n",
      "\n",
      "  Data_Identifier Routine_ID  DTC_Format Status_Mask Security_Level NRC_Code  \\\n",
      "0               -          -  ISO15031-6        0x00         Locked        -   \n",
      "1          0xF190          -  ISO15031-6        0x08       Unlocked        -   \n",
      "2               -          -  ISO15031-6        0x00         Locked        -   \n",
      "3               -          -  ISO15031-6        0x00         Locked        -   \n",
      "4          0xF15A          -  ISO15031-6        0x08       Unlocked        -   \n",
      "\n",
      "  Response_Time_ms  Effort_hours  \n",
      "0               45            16  \n",
      "1               38            24  \n",
      "2               42            40  \n",
      "3               12             8  \n",
      "4               48            32  \n",
      "\n",
      "üìä Dataset Statistics:\n",
      "       Effort_hours\n",
      "count     66.000000\n",
      "mean      26.303030\n",
      "std       12.414594\n",
      "min        8.000000\n",
      "25%       16.000000\n",
      "50%       24.000000\n",
      "75%       32.000000\n",
      "max       64.000000\n",
      "\n",
      "=== Training Model ===\n",
      "Preparing features...\n",
      "  Converting hexadecimal values...\n",
      "  Counting data identifiers...\n",
      "  Creating binary features...\n",
      "  Processing response time...\n",
      "  Encoding categorical variables...\n",
      "Dataset shape: (66, 10)\n",
      "Target range: 8 - 64 hours\n",
      "Training set: 62 samples\n",
      "Test set: 4 samples\n",
      "\n",
      "Training Random Forest model...\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "‚úÖ Model trained successfully!\n",
      "\n",
      "Training Performance:\n",
      "  Mean Absolute Error: 3.38 hours\n",
      "  R¬≤ Score: 0.843\n",
      "\n",
      "Test Performance:\n",
      "  Mean Absolute Error: 9.27 hours\n",
      "  R¬≤ Score: -0.663\n",
      "\n",
      "üìä Top 5 Most Important Features:\n",
      "  Service_ID_numeric: 0.5032\n",
      "  Response_Time_ms_numeric: 0.2727\n",
      "  Sub_function_numeric: 0.1350\n",
      "  Session_Type_encoded: 0.0358\n",
      "  Status_Mask_numeric: 0.0228\n",
      "\n",
      "üìà Feature importance plot saved to: feature_importance.png\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE PREDICTIONS\n",
      "======================================================================\n",
      "  Converting hexadecimal values...\n",
      "  Counting data identifiers...\n",
      "  Creating binary features...\n",
      "  Processing response time...\n",
      "  Encoding categorical variables...\n",
      "\n",
      "üîπ Example 1: Extended Session - ReadDataByIdentifier\n",
      "   Predicted effort: 23 hours\n",
      "  Converting hexadecimal values...\n",
      "  Counting data identifiers...\n",
      "  Creating binary features...\n",
      "  Processing response time...\n",
      "  Encoding categorical variables...\n",
      "\n",
      "üîπ Example 2: Programming Session - RoutineControl\n",
      "   Predicted effort: 46 hours\n",
      "  Converting hexadecimal values...\n",
      "  Counting data identifiers...\n",
      "  Creating binary features...\n",
      "  Processing response time...\n",
      "  Encoding categorical variables...\n",
      "\n",
      "üîπ Example 3: Default Session - TesterPresent\n",
      "   Predicted effort: 11 hours\n",
      "\n",
      "======================================================================\n",
      "‚úÖ PROCESS COMPLETED SUCCESSFULLY\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "93f5c9a73243e55b"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
