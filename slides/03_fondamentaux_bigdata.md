# Les fondamentaux du Big Data

## DurÃ©e : 2h30 (avec cas pratique)

---

## Objectifs de ce module

- Comprendre les 5V du Big Data
- DÃ©couvrir l'architecture d'un systÃ¨me Big Data
- Manipuler des donnÃ©es rÃ©elles de capteurs automobiles
- Visualiser et analyser des donnÃ©es massives

---

## Qu'est-ce que le Big Data ?

### DÃ©finition

> **"Ensemble de donnÃ©es si volumineuses qu'elles dÃ©passent les capacitÃ©s des outils traditionnels"**

**Outils traditionnels :**
- Excel : Limite ~ 1 million de lignes
- Base de donnÃ©es classique : Ralentit fortement au-delÃ  de quelques millions d'enregistrements
- Traitement sÃ©quentiel sur une seule machine

**Big Data :**
- Milliards d'enregistrements
- Traitement distribuÃ© sur des clusters de serveurs
- Technologies spÃ©cialisÃ©es (Hadoop, Spark, etc.)

---

### Exemples automobiles

| Source | Volume par vÃ©hicule | Parc de 1 million |
|--------|---------------------|-------------------|
| **Capteurs embarquÃ©s** | 4 To/jour | 4 Po/jour |
| **Logs calculateurs** | 100 Mo/jour | 100 To/jour |
| **DonnÃ©es GPS** | 50 Mo/jour | 50 To/jour |
| **Maintenance** | 1 Mo/visite | Variable |

**Po = PÃ©taoctet = 1 000 To = 1 000 000 Go**

Une seule flotte de vÃ©hicules connectÃ©s gÃ©nÃ¨re plusieurs pÃ©taoctets par jour !

---

## Les 5V du Big Data

```
    Volume
       â”‚
   VÃ©locitÃ© â”€â”€â”€â”€ BIG DATA â”€â”€â”€â”€ VariÃ©tÃ©
       â”‚
    VÃ©racitÃ© â”€â”€â”€â”€ Valeur
```

---

### 1. Volume

**La quantitÃ© massive de donnÃ©es**

#### Ordres de grandeur

- **MÃ©gaoctet (Mo)** : Une photo haute rÃ©solution
- **Gigaoctet (Go)** : Un film HD
- **TÃ©raoctet (To)** : 1 000 Go - Disque dur standard
- **PÃ©taoctet (Po)** : 1 000 To - Datacenter moyen
- **Exaoctet (Eo)** : 1 000 Po - Les plus grands datacenters
- **Zettaoctet (Zo)** : 1 000 Eo - DonnÃ©es mondiales gÃ©nÃ©rÃ©es/an

---

#### Exemple Stellantis/Renault

**HypothÃ¨ses :**
- 2 millions de vÃ©hicules connectÃ©s
- Chaque vÃ©hicule gÃ©nÃ¨re 1 Go/jour de tÃ©lÃ©mÃ©trie

**Volume :**
- **Par jour** : 2 Po
- **Par an** : 730 Po = 0,73 Eo

**ConsÃ©quences :**
- Impossible de stocker sur une seule machine
- NÃ©cessite un systÃ¨me de stockage distribuÃ©
- CoÃ»ts de stockage significatifs (mais dÃ©croissants)

---

#### Solutions pour gÃ©rer le Volume

**Stockage distribuÃ© :**
- **HDFS (Hadoop Distributed File System)** : Fichiers rÃ©partis sur plusieurs serveurs
- **Cloud Storage** : Google Cloud Storage, AWS S3, Azure Blob
- **Data Lakes** : Stockage centralisÃ© de toutes les donnÃ©es brutes

**Compression :**
- Formats efficaces : Parquet, ORC, Avro
- RÃ©duction de 70-90% de la taille
- Exemple : CSV 10 Go â†’ Parquet 1 Go

**Archivage :**
- DonnÃ©es chaudes (accÃ¨s frÃ©quent) : SSD
- DonnÃ©es tiÃ¨des (accÃ¨s occasionnel) : HDD
- DonnÃ©es froides (rarement accÃ©dÃ©es) : Cloud glacial

---

### 2. VÃ©locitÃ©

**La vitesse de gÃ©nÃ©ration et de traitement des donnÃ©es**

#### Trois types de traitement

| Type | Latence | Exemple automobile |
|------|---------|-------------------|
| **Batch** | Heures/jours | Analyse mensuelle des ventes |
| **Near Real-Time** | Minutes/secondes | DÃ©tection d'anomalies de flotte |
| **Real-Time** | Millisecondes | Freinage d'urgence automatique |

---

#### Cas d'usage : ADAS en temps rÃ©el

**Contrainte :** DÃ©cision en < 100 ms

**Pipeline :**
1. Capteurs (camÃ©ras, radars) : GÃ©nÃ©ration donnÃ©es â†’ 50 ms
2. Traitement image (dÃ©tection obstacle) â†’ 30 ms
3. DÃ©cision et action (freiner) â†’ 20 ms

**Total : 100 ms = 0,1 seconde**

**Technologie :** Edge Computing (traitement dans le vÃ©hicule)

---

#### Technologies pour la vÃ©locitÃ©

**Streaming de donnÃ©es :**
- **Apache Kafka** : SystÃ¨me de messages distribuÃ©s
- **Apache Flink** : Traitement de flux en temps rÃ©el
- **Spark Streaming** : Extension Spark pour donnÃ©es en flux

**Exemple d'architecture :**
```
VÃ©hicules â†’ Kafka â†’ Spark Streaming â†’ Alertes
                          â†“
                      Stockage
```

**Use case :** DÃ©tection en temps rÃ©el de conduite dangereuse

---

### 3. VariÃ©tÃ©

**La diversitÃ© des types de donnÃ©es**

#### Classification

**1. DonnÃ©es structurÃ©es (20%)**
- Format fixe, tableaux
- Bases de donnÃ©es relationnelles
- Exemple : Historique de ventes

| VIN | Date | ModÃ¨le | Prix |
|-----|------|--------|------|
| 1234 | 2024-01-15 | Clio | 18000 |

---

**2. DonnÃ©es semi-structurÃ©es (10%)**
- Structure flexible (JSON, XML)
- Logs applicatifs
- Exemple : Log calculateur

```json
{
  "timestamp": "2024-11-02T14:30:00Z",
  "vin": "VF1234567890",
  "event": "ENGINE_TEMP_HIGH",
  "temperature": 98.5,
  "location": {"lat": 48.8566, "lon": 2.3522}
}
```

---

**3. DonnÃ©es non structurÃ©es (70%)**
- Pas de format prÃ©dÃ©fini
- Images, vidÃ©os, audio, texte libre
- Exemple :
  - VidÃ©os des camÃ©ras ADAS
  - Notes de maintenance (texte libre)
  - Enregistrements vocaux du support client

**DÃ©fi :** Extraire de la valeur de ces donnÃ©es

---

#### Exemple automobile : Fusion de donnÃ©es

**Pour prÃ©dire une panne moteur, on combine :**

1. **StructurÃ©es** :
   - KilomÃ©trage, Ã¢ge vÃ©hicule, historique entretien

2. **Semi-structurÃ©es** :
   - Logs calculateur (JSON)
   - DonnÃ©es CAN bus

3. **Non structurÃ©es** :
   - Notes mÃ©canicien ("bruit inhabituel au dÃ©marrage")
   - Photos de piÃ¨ces usÃ©es

**Technologies :**
- Bases de donnÃ©es NoSQL (MongoDB, Cassandra)
- Data Lakes (stockage unifiÃ©)
- NLP pour analyser le texte

---

### 4. VÃ©racitÃ©

**La qualitÃ© et la fiabilitÃ© des donnÃ©es**

#### ProblÃ¨mes courants

âŒ **DonnÃ©es manquantes**
```
VIN: 1234, TempÃ©rature: NULL, Pression: 2.1 bar
```
â†’ Capteur dÃ©faillant ? DonnÃ©e non enregistrÃ©e ?

âŒ **DonnÃ©es aberrantes**
```
TempÃ©rature moteur: -273Â°C
```
â†’ Impossible physiquement (0 Kelvin)

âŒ **DonnÃ©es contradictoires**
```
Source A: VÃ©hicule en France
Source B (GPS): VÃ©hicule au Japon (mÃªme instant)
```

âŒ **DonnÃ©es obsolÃ¨tes**
```
DerniÃ¨re mise Ã  jour: Il y a 6 mois
```
â†’ Encore pertinente ?

---

#### Impact sur l'IA

**RÃ¨gle d'or :**
> "Garbage In, Garbage Out" (GIGO)

**ConsÃ©quences :**
- ModÃ¨le ML entraÃ®nÃ© sur donnÃ©es de mauvaise qualitÃ© â†’ PrÃ©dictions erronÃ©es
- DÃ©cisions business basÃ©es sur donnÃ©es fausses â†’ Pertes financiÃ¨res
- SÃ©curitÃ© compromise (ex: ADAS avec capteurs dÃ©faillants)

**Statistique :**
- Les data scientists passent 80% de leur temps Ã  nettoyer les donnÃ©es
- Seulement 20% sur la modÃ©lisation

---

#### Solutions pour amÃ©liorer la vÃ©racitÃ©

**1. Validation Ã  la source**
```python
if temperature < -50 or temperature > 150:
    flag_as_anomaly()
```

**2. DÃ©tection d'anomalies**
- Algorithmes statistiques
- Machine Learning (Isolation Forest, Autoencoders)

**3. RÃ¨gles mÃ©tier**
```python
if kilomÃ©trage < kilomÃ©trage_prÃ©cÃ©dent:
    raise DataError("KilomÃ©trage ne peut pas diminuer")
```

**4. TraÃ§abilitÃ©**
- Qui a crÃ©Ã© la donnÃ©e ?
- Quand ?
- Quelle version du capteur/logiciel ?

**5. Master Data Management (MDM)**
- RÃ©fÃ©rentiel unique (ex: liste VINs valides)
- DÃ©doublonnage

---

### 5. Valeur

**Transformer les donnÃ©es en insights actionnables**

> "Les donnÃ©es n'ont de valeur que si elles mÃ¨nent Ã  l'action"

#### Pyramide de la valeur

```
        DÃ©cisions & Actions
              â†‘
         Insights (Pourquoi ?)
              â†‘
      Analytics (Quoi ?)
              â†‘
         Informations
              â†‘
          DonnÃ©es brutes
```

---

#### Exemple : De la donnÃ©e Ã  la dÃ©cision

**Niveau 1 : DonnÃ©es brutes**
```
VIN1: 15000 km, 2 ans, 0 pannes
VIN2: 180000 km, 10 ans, 3 pannes
VIN3: 95000 km, 5 ans, 1 panne
... (100 000 vÃ©hicules)
```

**Niveau 2 : Information**
```
Ã‚ge moyen du parc: 6,2 ans
KilomÃ©trage moyen: 85 000 km
```

**Niveau 3 : Analyse**
```
Les vÃ©hicules > 150 000 km ont 4x plus de pannes
```

**Niveau 4 : Insight**
```
Les clients avec vÃ©hicules haute kilomÃ©trie
sont les plus coÃ»teux en SAV
```

**Niveau 5 : DÃ©cision**
```
Actions:
1. Cibler ces clients pour renouvellement
2. Adapter l'offre de garantie Ã©tendue
3. Optimiser stock piÃ¨ces dÃ©tachÃ©es
```

---

#### Mesurer la valeur

**ROI (Return on Investment)**

**Exemple : Projet maintenance prÃ©dictive**

**CoÃ»ts :**
- Infrastructure Big Data : 500 kâ‚¬
- Ã‰quipe (3 personnes, 1 an) : 300 kâ‚¬
- **Total : 800 kâ‚¬**

**Gains :**
- RÃ©duction rappels : 2 Mâ‚¬/an
- AmÃ©lioration satisfaction client : 500 kâ‚¬/an
- **Total : 2,5 Mâ‚¬/an**

**ROI = (2,5 - 0,8) / 0,8 = 212%**
**Retour sur investissement en 4 mois**

---

## Architecture d'un systÃ¨me Big Data

### Vue d'ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SOURCES DE DONNÃ‰ES                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VÃ©hicules | Usines | Web | Fournisseurs | ... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INGESTION / COLLECTE               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Kafka | ETL | APIs | IoT Hub | Scrapers     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STOCKAGE (Data Lake)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Raw Data | HDFS | Cloud Storage | Databases    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRAITEMENT / ANALYSE               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Spark | Hadoop | Presto | Machine Learning     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VISUALISATION / SERVING            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dashboards | APIs | Reports | Applications     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1. Couche d'ingestion

**RÃ´le : Collecter les donnÃ©es de sources hÃ©tÃ©rogÃ¨nes**

#### Technologies clÃ©s

**Apache Kafka**
- SystÃ¨me de messaging distribuÃ©
- Haute disponibilitÃ©
- Gestion de millions d'Ã©vÃ©nements/seconde

**ETL (Extract, Transform, Load)**
- Extract : RÃ©cupÃ©ration donnÃ©es sources
- Transform : Nettoyage, formatage
- Load : Chargement dans le systÃ¨me cible

**IoT Hubs**
- Azure IoT Hub, AWS IoT Core
- SpÃ©cialisÃ©s pour donnÃ©es capteurs

---

#### Exemple : Ingestion de donnÃ©es vÃ©hicules

```
Flotte vÃ©hicules (2M)
    â”‚
    â”œâ”€â”€ 4G/5G Connection
    â”‚
    â†“
Kafka Topic: "vehicle_telemetry"
    â”‚
    â”œâ”€â”€ Partition 1 : VÃ©hicules rÃ©gion Nord
    â”œâ”€â”€ Partition 2 : VÃ©hicules rÃ©gion Sud
    â””â”€â”€ Partition 3 : VÃ©hicules rÃ©gion Est/Ouest
    â”‚
    â†“
Data Lake (stockage brut)
```

**BÃ©nÃ©fices :**
- ScalabilitÃ© : Ajout facile de partitions
- RÃ©silience : RÃ©plication des donnÃ©es
- DÃ©couplage : Producteurs et consommateurs indÃ©pendants

---

### 2. Couche de stockage

**RÃ´le : Stocker les donnÃ©es de maniÃ¨re scalable et Ã©conomique**

#### Approches

**1. Data Warehouse (entrepÃ´t de donnÃ©es)**
- DonnÃ©es structurÃ©es, schÃ©ma dÃ©fini
- OptimisÃ© pour requÃªtes analytiques
- Exemples : Snowflake, BigQuery, Redshift

**2. Data Lake (lac de donnÃ©es)**
- Stockage brut de toutes donnÃ©es (structurÃ©es ou non)
- SchÃ©ma Ã  la lecture (schema-on-read)
- Exemples : HDFS, S3, Azure Data Lake

**3. Lakehouse**
- Fusion des deux approches
- Exemple : Databricks Lakehouse, Delta Lake

---

#### Comparaison

| CritÃ¨re | Data Warehouse | Data Lake |
|---------|----------------|-----------|
| **DonnÃ©es** | StructurÃ©es | Tous types |
| **SchÃ©ma** | Ã€ l'Ã©criture | Ã€ la lecture |
| **CoÃ»t** | Ã‰levÃ© | Ã‰conomique |
| **Performance** | Rapide (requÃªtes connues) | Variable |
| **FlexibilitÃ©** | Faible | Ã‰levÃ©e |
| **Usage** | BI, reporting | Data science, ML |

---

#### Organisation d'un Data Lake

```
Data Lake
â”‚
â”œâ”€â”€ raw/                      # DonnÃ©es brutes
â”‚   â”œâ”€â”€ vehicle_telemetry/
â”‚   â”œâ”€â”€ maintenance_logs/
â”‚   â””â”€â”€ sales/
â”‚
â”œâ”€â”€ processed/                # DonnÃ©es nettoyÃ©es
â”‚   â”œâ”€â”€ vehicle_telemetry_clean/
â”‚   â””â”€â”€ sales_enriched/
â”‚
â”œâ”€â”€ curated/                  # DonnÃ©es agrÃ©gÃ©es
â”‚   â”œâ”€â”€ daily_fleet_summary/
â”‚   â””â”€â”€ monthly_sales_kpis/
â”‚
â””â”€â”€ ml/                       # Datasets ML
    â”œâ”€â”€ predictive_maintenance/
    â””â”€â”€ customer_segmentation/
```

**Principe : "Zone d'atterrissage" â†’ "Zone transformÃ©e" â†’ "Zone consommation"**

---

### 3. Couche de traitement

**RÃ´le : Transformer et analyser les donnÃ©es**

#### Apache Spark

**Le framework de rÃ©fÃ©rence pour le Big Data**

**CaractÃ©ristiques :**
- Traitement distribuÃ© en mÃ©moire (100x plus rapide que Hadoop)
- API en Python (PySpark), Scala, Java, R
- GÃ¨re batch et streaming
- IntÃ¨gre ML (MLlib)

---

#### Exemple : Analyse avec PySpark

**ProblÃ¨me :** Calculer la tempÃ©rature moteur moyenne par modÃ¨le de vÃ©hicule

**DonnÃ©es :** 10 milliards d'enregistrements de tÃ©lÃ©mÃ©trie

```python
from pyspark.sql import SparkSession

# Initialiser Spark
spark = SparkSession.builder.appName("TempAnalysis").getOrCreate()

# Lire les donnÃ©es (format Parquet)
df = spark.read.parquet("gs://bucket/vehicle_telemetry/")

# Analyse
result = df.groupBy("vehicle_model") \
           .agg({"engine_temp": "avg"}) \
           .orderBy("avg(engine_temp)", ascending=False)

# Afficher
result.show()
```

**RÃ©sultat en quelques minutes sur un cluster**, mÃªme avec milliards de lignes !

---

#### Pourquoi Spark est distribuÃ© ?

**Architecture :**

```
Driver (coordonne)
    â”‚
    â”œâ”€â”€ Worker 1 (traite partition 1)
    â”œâ”€â”€ Worker 2 (traite partition 2)
    â”œâ”€â”€ Worker 3 (traite partition 3)
    â””â”€â”€ Worker N (traite partition N)
```

**ParallÃ©lisation automatique :**
- DonnÃ©es rÃ©parties sur N workers
- Chaque worker traite sa partition
- AgrÃ©gation finale des rÃ©sultats

**Exemple :**
- 10 milliards de lignes
- 100 workers
- Chaque worker traite 100 millions de lignes
- Temps divisÃ© par 100 !

---

### 4. Couche de visualisation

**RÃ´le : Rendre les insights accessibles aux utilisateurs**

#### Outils

**Business Intelligence :**
- **Tableau** : Visualisations interactives
- **Power BI** : IntÃ©gration Microsoft
- **Looker** : Analytics moderne
- **Superset** : Open source (Apache)

**Notebooks :**
- **Jupyter** : Standard data science
- **Databricks Notebooks** : IntÃ©grÃ© Spark

**Dashboards custom :**
- Applications web (React, Vue.js)
- APIs REST pour intÃ©gration

---

#### Exemple de dashboard pour flotte automobile

**KPIs principaux :**

ğŸ“Š **Vue d'ensemble**
- Nombre de vÃ©hicules actifs
- KilomÃ©trage total parcouru (aujourd'hui)
- Alertes critiques en cours

ğŸ“ˆ **Tendances**
- Ã‰volution tempÃ©rature moteur moyenne (7 jours)
- Distribution kilomÃ©trage journalier
- Top 10 codes d'erreur

ğŸ—ºï¸ **Carte gÃ©ographique**
- Localisation des vÃ©hicules
- Heatmap des zones de conduite

âš ï¸ **Alertes**
- VÃ©hicules avec anomalies dÃ©tectÃ©es
- PrÃ©dictions de pannes (7 jours)

---

## Technologies de l'Ã©cosystÃ¨me Big Data

### Stockage distribuÃ©

- **HDFS (Hadoop Distributed File System)** : Historique, toujours utilisÃ©
- **Amazon S3** : Stockage objet cloud le plus populaire
- **Google Cloud Storage** : Alternative GCP
- **Azure Blob Storage** : Alternative Azure

---

### Traitement batch

- **Hadoop MapReduce** : Premier framework (obsolÃ¨te)
- **Apache Spark** : Standard actuel
- **Apache Flink** : Concurrent de Spark
- **Presto** : RequÃªtes SQL sur data lake

---

### Traitement streaming

- **Apache Kafka** : Plateforme de streaming #1
- **Apache Flink** : Excellent pour streaming
- **Spark Streaming** : Extension Spark
- **Amazon Kinesis** : Managed sur AWS

---

### Bases de donnÃ©es NoSQL

**Key-Value :**
- **Redis** : In-memory, ultra-rapide
- **DynamoDB** : AWS managed

**Document :**
- **MongoDB** : Le plus populaire
- **Couchbase** : Performant

**Column-family :**
- **Cassandra** : Haute disponibilitÃ©
- **HBase** : BasÃ© sur Hadoop

**Graph :**
- **Neo4j** : Relations complexes

---

### Orchestration

- **Apache Airflow** : Orchestration de workflows (le plus utilisÃ©)
- **Luigi** : Alternative Spotify
- **Argo** : Pour Kubernetes

**RÃ´le :** Planifier et coordonner les jobs
- Exemple : "Tous les jours Ã  2h, extraire les donnÃ©es, les transformer, et gÃ©nÃ©rer les rapports"

---

## Cas pratique : Visualisation de donnÃ©es capteurs embarquÃ©s

### Objectif

Analyser et visualiser des donnÃ©es rÃ©elles de capteurs provenant de vÃ©hicules Volvo (dataset RIIB)

**Dataset RIIB (Robot for Interaction in Buildings)**
- Images de camÃ©ras embarquÃ©es
- DonnÃ©es de capteurs (LIDAR, odomÃ©trie)
- Cas d'usage : Navigation autonome

---

### DÃ©roulement (1h15)

**1. Introduction au dataset (10 min)**
- PrÃ©sentation de la structure
- Types de donnÃ©es disponibles

**2. Exploration avec notebook Python (45 min)**
- Chargement des donnÃ©es
- Nettoyage et prÃ©paration
- Visualisations (matplotlib, seaborn)
- Analyse statistique

**3. Questions / Discussion (20 min)**
- InterprÃ©tation des rÃ©sultats
- Lien avec vos projets

---

### Notebook pratique

**â†’ Passage au notebook Jupyter**

`notebooks/01_visualisation_capteurs_riib.ipynb`

Nous allons :
1. Charger des images de camÃ©ras
2. Analyser des donnÃ©es de trajectoires
3. CrÃ©er des visualisations interactives
4. Calculer des statistiques sur les donnÃ©es de capteurs

---

## Points clÃ©s Ã  retenir

### Les 5V du Big Data

1. **Volume** : Stockage distribuÃ© nÃ©cessaire (Po de donnÃ©es)
2. **VÃ©locitÃ©** : Batch, near real-time, ou real-time selon le besoin
3. **VariÃ©tÃ©** : StructurÃ© (20%), semi-structurÃ© (10%), non-structurÃ© (70%)
4. **VÃ©racitÃ©** : QualitÃ© cruciale (GIGO : Garbage In, Garbage Out)
5. **Valeur** : Objectif ultime â†’ DÃ©cisions actionnables

---

### Architecture Big Data

```
Sources â†’ Ingestion (Kafka) â†’ Stockage (Data Lake)
       â†’ Traitement (Spark) â†’ Visualisation (BI)
```

**Principes :**
- Distribution pour la scalabilitÃ©
- DÃ©couplage des couches
- Schema-on-read pour la flexibilitÃ©

---

### Technologies essentielles

| Besoin | Technologie |
|--------|-------------|
| Stockage | HDFS, S3, GCS |
| Traitement batch | Spark |
| Traitement streaming | Kafka, Flink |
| Bases NoSQL | MongoDB, Cassandra |
| Orchestration | Airflow |
| Visualisation | Tableau, Power BI |

---

## Pour aller plus loin

### Livres
- "Designing Data-Intensive Applications" - Martin Kleppmann (bible)
- "Big Data: Principles and best practices" - Nathan Marz

### Cours
- Coursera : "Big Data Specialization" (UC San Diego)
- Databricks Academy : Formation Spark officielle

### Certifications
- **Databricks Certified Data Engineer**
- **Google Professional Data Engineer**
- **AWS Certified Big Data - Specialty**

---

## Fin du Jour 1

### RÃ©capitulatif

**Matin :**
- âœ… Introduction Ã  l'IA et Big Data dans l'automobile
- âœ… Les trois types d'apprentissage (supervisÃ©, non supervisÃ©, renforcement)
- âœ… Lecture critique d'un projet IA

**AprÃ¨s-midi :**
- âœ… Les 5V du Big Data
- âœ… Architecture d'un systÃ¨me Big Data
- âœ… Cas pratique avec donnÃ©es rÃ©elles

---

### Demain â€“ Jour 2

**Matin :**
- Cas d'usage concrets (maintenance prÃ©dictive, analyse comportementale, logistique)
- Ã‰tude de cas : IA embarquÃ©e dans vÃ©hicules connectÃ©s

**AprÃ¨s-midi :**
- Ã‰valuer un projet IA (mÃ©thodologie, biais, RGPD)
- Identifier des pistes d'action pour votre entreprise
- Conclusion et plan d'action individuel

---

### Questions / Discussion

**ThÃ¨mes de discussion :**
- Quels sont les principaux dÃ©fis Big Data dans votre service ?
- Quelles donnÃ©es collectez-vous actuellement ?
- Quels cas d'usage vous semblent les plus pertinents ?

---

## Annexe : Glossaire Big Data

**Batch processing** : Traitement de donnÃ©es par lots (heures/jours)

**Cluster** : Ensemble de serveurs travaillant ensemble

**Data Lake** : Stockage centralisÃ© de toutes les donnÃ©es brutes

**Data Warehouse** : EntrepÃ´t de donnÃ©es structurÃ©es pour l'analyse

**Distributed system** : SystÃ¨me rÃ©parti sur plusieurs machines

**ETL** : Extract, Transform, Load (processus de chargement de donnÃ©es)

**HDFS** : Hadoop Distributed File System (stockage distribuÃ©)

**Lakehouse** : Architecture combinant data lake et data warehouse

**NoSQL** : Bases de donnÃ©es non relationnelles

**Parquet** : Format de fichier colonnaire optimisÃ© pour Big Data

**Partition** : Subdivision de donnÃ©es pour traitement parallÃ¨le

**Schema-on-read** : SchÃ©ma dÃ©fini lors de la lecture (vs Ã  l'Ã©criture)

**Streaming** : Traitement de donnÃ©es en flux continu

**Worker** : Serveur exÃ©cutant une partie du traitement distribuÃ©
